{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence_transformers"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 23.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
      "     ---------------------------------------- 86.0/86.0 kB 1.6 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting transformers<5.0.0,>=4.6.0 (from sentence_transformers)\n",
      "  Downloading transformers-4.31.0-py3-none-any.whl (7.4 MB)\n",
      "     ---------------------------------------- 7.4/7.4 MB 6.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: tqdm in c:\\users\\hboyz\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from sentence_transformers) (4.64.1)\n",
      "Collecting torch>=1.6.0 (from sentence_transformers)\n",
      "  Downloading torch-2.0.1-cp39-cp39-win_amd64.whl (172.4 MB)\n",
      "     -------------------------------------- 172.4/172.4 MB 2.4 MB/s eta 0:00:00\n",
      "Collecting torchvision (from sentence_transformers)\n",
      "  Downloading torchvision-0.15.2-cp39-cp39-win_amd64.whl (1.2 MB)\n",
      "     ---------------------------------------- 1.2/1.2 MB 7.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy in c:\\users\\hboyz\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from sentence_transformers) (1.23.5)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\hboyz\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from sentence_transformers) (1.2.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\hboyz\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from sentence_transformers) (1.9.3)\n",
      "Requirement already satisfied: nltk in c:\\users\\hboyz\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from sentence_transformers) (3.8.1)\n",
      "Collecting sentencepiece (from sentence_transformers)\n",
      "  Downloading sentencepiece-0.1.99-cp39-cp39-win_amd64.whl (977 kB)\n",
      "     -------------------------------------- 977.6/977.6 kB 7.7 MB/s eta 0:00:00\n",
      "Collecting huggingface-hub>=0.4.0 (from sentence_transformers)\n",
      "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
      "     -------------------------------------- 268.8/268.8 kB 8.1 MB/s eta 0:00:00\n",
      "Collecting filelock (from huggingface-hub>=0.4.0->sentence_transformers)\n",
      "  Downloading filelock-3.12.2-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: fsspec in c:\\users\\hboyz\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2023.1.0)\n",
      "Requirement already satisfied: requests in c:\\users\\hboyz\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2.28.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\hboyz\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\hboyz\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.5.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\hboyz\\appdata\\roaming\\python\\python39\\site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (21.3)\n",
      "Collecting sympy (from torch>=1.6.0->sentence_transformers)\n",
      "  Downloading sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "     ---------------------------------------- 5.7/5.7 MB 3.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: networkx in c:\\users\\hboyz\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch>=1.6.0->sentence_transformers) (3.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\hboyz\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch>=1.6.0->sentence_transformers) (3.1.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\hboyz\\appdata\\roaming\\python\\python39\\site-packages (from tqdm->sentence_transformers) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\hboyz\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2022.10.31)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers<5.0.0,>=4.6.0->sentence_transformers)\n",
      "  Downloading tokenizers-0.13.3-cp39-cp39-win_amd64.whl (3.5 MB)\n",
      "     ---------------------------------------- 3.5/3.5 MB 3.6 MB/s eta 0:00:00\n",
      "Collecting safetensors>=0.3.1 (from transformers<5.0.0,>=4.6.0->sentence_transformers)\n",
      "  Downloading safetensors-0.3.1-cp39-cp39-win_amd64.whl (263 kB)\n",
      "     -------------------------------------- 263.9/263.9 kB 4.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: click in c:\\users\\hboyz\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nltk->sentence_transformers) (8.1.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\hboyz\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nltk->sentence_transformers) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\hboyz\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn->sentence_transformers) (3.1.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\hboyz\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torchvision->sentence_transformers) (9.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\hboyz\\appdata\\roaming\\python\\python39\\site-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence_transformers) (3.0.9)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\hboyz\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jinja2->torch>=1.6.0->sentence_transformers) (2.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hboyz\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hboyz\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\hboyz\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hboyz\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2022.12.7)\n",
      "Collecting mpmath>=0.19 (from sympy->torch>=1.6.0->sentence_transformers)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "     -------------------------------------- 536.2/536.2 kB 8.3 MB/s eta 0:00:00\n",
      "Building wheels for collected packages: sentence_transformers\n",
      "  Building wheel for sentence_transformers (setup.py): started\n",
      "  Building wheel for sentence_transformers (setup.py): finished with status 'done'\n",
      "  Created wheel for sentence_transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125973 sha256=3ef4e864a987979518079dc0c114dc7f5d73f5cc57d817eaf4435782432e9207\n",
      "  Stored in directory: c:\\users\\hboyz\\appdata\\local\\pip\\cache\\wheels\\71\\67\\06\\162a3760c40d74dd40bc855d527008d26341c2b0ecf3e8e11f\n",
      "Successfully built sentence_transformers\n",
      "Installing collected packages: tokenizers, sentencepiece, safetensors, mpmath, sympy, filelock, torch, huggingface-hub, transformers, torchvision, sentence_transformers\n",
      "Successfully installed filelock-3.12.2 huggingface-hub-0.16.4 mpmath-1.3.0 safetensors-0.3.1 sentence_transformers-2.2.2 sentencepiece-0.1.99 sympy-1.12 tokenizers-0.13.3 torch-2.0.1 torchvision-0.15.2 transformers-4.31.0\n"
     ]
    }
   ],
   "source": [
    "# !pip install sentence_transformers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: I want to code using pandas dataframes\n",
      "\n",
      "Python bootcamp certificate  ----->   0.14652766\n",
      "Google UX Designer  ----->   -0.021529071\n",
      "IBM Full stack developer  ----->   0.10523875\n",
      "Business Intelligence  ----->   0.13626488\n",
      "IBM Data Engineering  ----->   0.18579663\n",
      "Master in Graphic Design  ----->   -0.0044896645\n",
      "Tools: MySQL, PostgresSQL, Python, R Programming, Tableau, Airflow, Figma  ----->   0.201324\n",
      "Skills: Data Extraction, Data Manipulation, Data Analysis, Data Transformation, Machine Learning, Descriptive Analysis, Predictive Analysis, Prescriptive Analysis  ----->   0.17101842\n",
      "Master in Business Analytics  ----->   0.05035586\n",
      "Domain knowledge: Manufacturing, Software Development, Memory and Storage industry, International Logistics  ----->   0.03655469\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from numpy.linalg import norm\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Define the model we want to use (it'll download itself)\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "sentences = [\n",
    "  \"Python bootcamp certificate\",\n",
    "  \"Google UX Designer\",\n",
    "  \"IBM Full stack developer\",\n",
    "  \"Business Intelligence\",\n",
    "  \"IBM Data Engineering\",\n",
    "  \"Master in Graphic Design\",\n",
    "  \"Tools: MySQL, PostgresSQL, Python, R Programming, Tableau, Airflow, Figma\",\n",
    "  \"Skills: Data Extraction, Data Manipulation, Data Analysis, Data Transformation, Machine Learning, Descriptive Analysis, Predictive Analysis, Prescriptive Analysis\",\n",
    "  \"Master in Business Analytics\",\n",
    "  \"Domain knowledge: Manufacturing, Software Development, Memory and Storage industry, International Logistics\"\n",
    "]\n",
    "\n",
    "# vector embeddings created from dataset\n",
    "embeddings = model.encode(sentences)\n",
    "\n",
    "string = \"I want to code using pandas dataframes\"\n",
    "# query vector embedding\n",
    "query_embedding = model.encode(f\"{string}\")\n",
    "\n",
    "# define our distance metric\n",
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b)/(norm(a)*norm(b))\n",
    "\n",
    "# run semantic similarity search\n",
    "print(f\"Query: {string}\\n\")\n",
    "for e, s in zip(embeddings, sentences):\n",
    "    print(s, \" ----->  \",\n",
    "         cosine_similarity(e, query_embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: I want to make a beautiful website\n",
      "\n",
      "Python bootcamp certificate  ----->   0.017453132\n",
      "Google UX Designer  ----->   0.27825183\n",
      "IBM Full stack developer  ----->   0.15243223\n",
      "Business Intelligence  ----->   0.18125758\n",
      "IBM Data Engineering  ----->   0.06649589\n",
      "Master in Graphic Design  ----->   0.21376713\n",
      "Tools: MySQL, PostgresSQL, Python, R Programming, Tableau, Airflow, Figma  ----->   0.15851252\n",
      "Skills: Data Extraction, Data Manipulation, Data Analysis, Data Transformation, Machine Learning, Descriptive Analysis, Predictive Analysis, Prescriptive Analysis  ----->   0.03422859\n",
      "Master in Business Analytics  ----->   0.054500088\n",
      "Domain knowledge: Manufacturing, Software Development, Memory and Storage industry, International Logistics  ----->   0.032579537\n"
     ]
    }
   ],
   "source": [
    "string = \"I want to make a beautiful website\"\n",
    "# query vector embedding\n",
    "query_embedding = model.encode(f\"{string}\")\n",
    "\n",
    "# define our distance metric\n",
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b)/(norm(a)*norm(b))\n",
    "\n",
    "# run semantic similarity search\n",
    "print(f\"Query: {string}\\n\")\n",
    "for e, s in zip(embeddings, sentences):\n",
    "    print(s, \" ----->  \",\n",
    "         cosine_similarity(e, query_embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: I want to make a master degree student to work with\n",
      "\n",
      "Python bootcamp certificate  ----->   0.017453132\n",
      "Google UX Designer  ----->   0.27825183\n",
      "IBM Full stack developer  ----->   0.15243223\n",
      "Business Intelligence  ----->   0.18125758\n",
      "IBM Data Engineering  ----->   0.06649589\n",
      "Master in Graphic Design  ----->   0.21376713\n",
      "Tools: MySQL, PostgresSQL, Python, R Programming, Tableau, Airflow, Figma  ----->   0.15851252\n",
      "Skills: Data Extraction, Data Manipulation, Data Analysis, Data Transformation, Machine Learning, Descriptive Analysis, Predictive Analysis, Prescriptive Analysis  ----->   0.03422859\n",
      "Master in Business Analytics  ----->   0.054500088\n",
      "Domain knowledge: Manufacturing, Software Development, Memory and Storage industry, International Logistics  ----->   0.032579537\n"
     ]
    }
   ],
   "source": [
    "string = \"I want to make a master degree student to work with\"\n",
    "# query vector embedding\n",
    "# query_embedding = model.encode(f\"{string}\")\n",
    "\n",
    "# define our distance metric\n",
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b)/(norm(a)*norm(b))\n",
    "\n",
    "# run semantic similarity search\n",
    "print(f\"Query: {string}\\n\")\n",
    "for e, s in zip(embeddings, sentences):\n",
    "    print(s, \" ----->  \",\n",
    "         cosine_similarity(e, query_embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "openai.api_key = os.environ.get('OPENAI_API_KEY')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "responsibilities_response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Using job description then return a list of major keywords in a list, name the list KEYWORDS\"},\n",
    "        {\"role\": \"user\", \"content\": \"\"\"Job description:\n",
    "                        \"\"\n",
    "                        Responsibilities:\n",
    "                        \n",
    "                        The Financial Analyst is a key player in creating and providing valuable information to healthcare administrators and external stakeholders across the US. The ideal candidate will be able to:\n",
    "                          \n",
    "                        Understand the current processes, systems, and products being used and identify areas of improvement. \n",
    "                        Create and understand complex Excel formulas.\n",
    "                        Dig into various levels of finance and healthcare data.\n",
    "                        Work well in a collaborative environment as well as independently.\n",
    "                        Create and maintain process documents to ensure repeatable results.\n",
    "                        Communicate professionally and timely with internal and external stakeholders\n",
    "                        Build and maintain complex Excel reports for healthcare professionals and stakeholders. \n",
    "                        Respond to monthly and ad hoc stakeholder reporting requirements and inquiries.\n",
    "                        Manage the capital expense reimbursement process.\n",
    "                        Assist with the M&A process and other finance department tasks and projects.\n",
    "                        Collaborate with other departments on various projects. \n",
    "                        QA testing to ensure accuracy and quality of data. \n",
    "                        Loading and pulling data from SQL databases/analysis services.\n",
    "                        \"\"\n",
    "                          return a list of major keywords in a list, name the list KEYWORDS          \n",
    "            \"\"\"}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "qualification_response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Using job description then return a list of major keywords in a list, name the list KEYWORDS\"},\n",
    "        {\"role\": \"user\", \"content\": \"\"\"Job description:\n",
    "                        \"\"\n",
    "                        Qualifications \n",
    "\n",
    "                        2-4 years of Finance or Accounting experience preferred\n",
    "                        Bachelorâ€™s in Finance, Accounting or similar\n",
    "                        Advanced Excel skills\n",
    "                        Understanding of financial statements/GL systems\n",
    "                        Knowledge of data warehouses, SQL, or VBA a plus\n",
    "                        Experience in a finance role preferred  \n",
    "                        \"\"\n",
    "                          return a list of major keywords in a list, name the list KEYWORDS          \n",
    "            \"\"\"}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' \\nFinancial Analyst', ' healthcare administrators', ' external stakeholders', ' processes', ' systems', ' products', ' areas of improvement', ' complex Excel formulas', ' finance', ' healthcare data', ' collaborative environment', ' process documents', ' repeatable results', ' professional communication', ' Excel reports', ' stakeholder reporting requirements', ' capital expense reimbursement process', ' M&A process', ' finance department tasks', ' projects', ' collaboration with other departments', ' QA testing', ' accuracy', ' quality of data', ' SQL databases/analysis services.']\n"
     ]
    }
   ],
   "source": [
    "# regular output\n",
    "keywords = responsibilities_response[\"choices\"][0][\"message\"][\"content\"].split(\":\")[1]\n",
    "keywords = keywords.split(\",\")\n",
    "print(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' Finance', ' Accounting', ' Excel skills', ' financial statements', ' GL systems', ' data warehouses', ' SQL', ' VBA', ' finance role', ' Qualifications', ' years of experience', \" Bachelor's degree\"]\n"
     ]
    }
   ],
   "source": [
    "# regular output\n",
    "keywords = qualification_response[\"choices\"][0][\"message\"][\"content\"].split(\":\")[1]\n",
    "keywords = keywords.split(\",\")\n",
    "print(keywords)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
